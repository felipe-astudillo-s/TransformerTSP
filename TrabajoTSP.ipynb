{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e36a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 0. IMPORTS\n",
    "# ==========================================\n",
    "#probando si esto se commitea\n",
    "#Nota de intiti: si van a trabajar desde un entorno local (Visual), \n",
    "# aseg√∫rense de tener instaladas las librer√≠as necesarias.\n",
    "#tutorial: ctrl + √± para abrir el terminal y luego pegar los siguientes comandos:\n",
    "#comando para instalar torch: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "#compando para instalar tqdm: pip install tqdm numpy matplotlib ortools\n",
    "#para instalar el request: pip install requests\n",
    "#tienen que esperar que se descarguen e instalen nom√°s \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import requests \n",
    "import gc # Garbage Collector para gesti√≥n de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e8365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU DETECTADA: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "   (Memoria disponible: 4.29 GB)\n",
      "\n",
      "‚öôÔ∏è Sincronizando con GitHub (felipe-astudillo-s/TransformerTSP)...\n",
      "üîç Consultando API para: Data/Easy...\n",
      "‚ùå Error 404: No existe la carpeta 'Data/Easy' en la rama 'main'.\n",
      "üîç Consultando API para: Data/Medium...\n",
      "‚úÖ Fase Data/Medium: 20 archivos listos en d:\\VISUAL\\gith\\TransformerTSP\\data_repo\\MEDIUM\n",
      "üîç Consultando API para: Data/Hard...\n",
      "‚ùå Error 404: No existe la carpeta 'Data/Hard' en la rama 'main'.\n",
      "\n",
      "üìÇ Rutas configuradas correctamente.\n",
      "üöÄ Listo para ejecutar el Bloque de Entrenamiento.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURACI√ìN, GPU Y DESCARGA DE DATOS\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# --- A. CONFIGURACI√ìN DEL HARDWARE (DEVICE) ---\n",
    "# Esto es vital para que el Bloque de entrenamiento sepa qu√© usar\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(f\"‚úÖ GPU DETECTADA: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   (Memoria disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB)\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"‚ö†Ô∏è GPU NO DETECTADA: Entrenando en CPU (ser√° lento).\")\n",
    "\n",
    "# --- B. CONFIGURACI√ìN DEL REPOSITORIO ---\n",
    "REPO_USER = \"felipe-astudillo-s\"\n",
    "REPO_NAME = \"TransformerTSP\"\n",
    "BRANCH = \"main\" # ‚ö†Ô∏è IMPORTANTE: Si tus datos no est√°n en 'main', cambia esto por el nombre de tu rama o commit.\n",
    "\n",
    "REPO_FOLDERS = {\n",
    "    \"EASY\":   \"Data/Easy\",\n",
    "    \"MEDIUM\": \"Data/Medium\",\n",
    "    \"HARD\":   \"Data/Hard\"\n",
    "}\n",
    "\n",
    "BASE_LOCAL_DIR = os.path.join(os.getcwd(), \"data_repo\")\n",
    "\n",
    "def download_folder_from_github(user, repo, repo_folder_path, local_output_dir, branch=\"main\"):\n",
    "    \"\"\"Descarga todos los .npz de una carpeta de GitHub usando la API.\"\"\"\n",
    "    api_url = f\"https://api.github.com/repos/{user}/{repo}/contents/{repo_folder_path}?ref={branch}\"\n",
    "    \n",
    "    print(f\"üîç Consultando API para: {repo_folder_path}...\")\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 404:\n",
    "            print(f\"‚ùå Error 404: No existe la carpeta '{repo_folder_path}' en la rama '{branch}'.\")\n",
    "            return local_output_dir\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Error API ({response.status_code}): {response.text}\")\n",
    "            return local_output_dir\n",
    "\n",
    "        files_list = response.json()\n",
    "        \n",
    "        if not os.path.exists(local_output_dir):\n",
    "            os.makedirs(local_output_dir)\n",
    "\n",
    "        if isinstance(files_list, dict) and 'message' in files_list:\n",
    "            print(\"‚ùå Error: La ruta parece no ser una carpeta v√°lida.\")\n",
    "            return local_output_dir\n",
    "\n",
    "        count = 0\n",
    "        for item in files_list:\n",
    "            if item['type'] == 'file' and item['name'].endswith('.npz'):\n",
    "                local_path = os.path.join(local_output_dir, item['name'])\n",
    "                if not os.path.exists(local_path):\n",
    "                    try:\n",
    "                        r = requests.get(item['download_url'])\n",
    "                        with open(local_path, 'wb') as f:\n",
    "                            f.write(r.content)\n",
    "                        count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"  ‚ùå Fall√≥ {item['name']}: {e}\")\n",
    "                else:\n",
    "                    count += 1 # Ya exist√≠a\n",
    "        \n",
    "        print(f\"‚úÖ Fase {repo_folder_path}: {count} archivos listos en {local_output_dir}\")\n",
    "        return local_output_dir\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error de conexi√≥n: {e}\")\n",
    "        return local_output_dir\n",
    "\n",
    "# --- C. EJECUCI√ìN DE DESCARGA ---\n",
    "PATHS = {}\n",
    "print(f\"\\n‚öôÔ∏è Sincronizando con GitHub ({REPO_USER}/{REPO_NAME})...\")\n",
    "\n",
    "for phase_name, repo_path in REPO_FOLDERS.items():\n",
    "    local_target = os.path.join(BASE_LOCAL_DIR, phase_name)\n",
    "    final_path = download_folder_from_github(REPO_USER, REPO_NAME, repo_path, local_target, BRANCH)\n",
    "    PATHS[phase_name] = final_path\n",
    "\n",
    "# --- D. CURRICULUM ---\n",
    "CURRICULUM = [\n",
    "    {\"phase\": \"EASY\",   \"epochs\": 20, \"lr\": 1e-3, \"bs\": 128},\n",
    "    {\"phase\": \"MEDIUM\", \"epochs\": 15, \"lr\": 1e-4, \"bs\": 64},\n",
    "    {\"phase\": \"HARD\",   \"epochs\": 30, \"lr\": 1e-4, \"bs\": 32}\n",
    "]\n",
    "\n",
    "print(f\"\\nüìÇ Rutas configuradas correctamente.\")\n",
    "print(f\"üöÄ Listo para ejecutar el Bloque de Entrenamiento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3ed76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. ARQUITECTURA DEL MODELO (POINTER NETWORK)\n",
    "# ==========================================\n",
    "\n",
    "# ENCODER (Sin Positional Encoding y con return memory)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=128, nhead=8, num_layers=3, dim_feedforward=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        # x: [batch, seq_len, input_dim]\n",
    "        h = self.input_proj(x)  # [B, S, d_model]\n",
    "\n",
    "        memory = self.encoder(h, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        return memory\n",
    "\n",
    "\n",
    "# --- 2. DECODER\n",
    "class PointerDecoder(nn.Module):\n",
    "    def __init__(self, d_model=128, nhead=8, num_layers=2, dropout=0.1, max_seq_len=128):\n",
    "        super().__init__()\n",
    "        self.start_token = nn.Parameter(torch.randn(1, 1, d_model))\n",
    "        self.step_emb = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model*4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        self.query_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, memory, tgt_indices=None, mask_visited=None, teacher_forcing=True):\n",
    "        B, S, d = memory.size()\n",
    "        device = memory.device\n",
    "        max_T = tgt_indices.size(1) if (tgt_indices is not None and teacher_forcing) else S\n",
    "\n",
    "        start = self.start_token.expand(B, -1, -1)\n",
    "        logits_steps = []\n",
    "        decoder_inputs = start\n",
    "        current_mask = torch.zeros(B, S, dtype=torch.bool).to(device)\n",
    "\n",
    "        for t in range(max_T):\n",
    "            step_emb = self.step_emb(torch.tensor([t], device=device)).unsqueeze(0).expand(B, -1, -1)\n",
    "            dec_in = decoder_inputs + step_emb\n",
    "            dec_out = self.decoder(dec_in, memory, memory_key_padding_mask=None)\n",
    "\n",
    "            q_t = dec_out[:, -1, :]\n",
    "            q = self.query_proj(q_t).unsqueeze(1)\n",
    "\n",
    "            scores = torch.matmul(q, memory.transpose(1,2)) / math.sqrt(d)\n",
    "            scores = scores.squeeze(1)\n",
    "\n",
    "            if not teacher_forcing:\n",
    "                scores = scores.masked_fill(current_mask, float('-inf'))\n",
    "\n",
    "            logits_steps.append(scores)\n",
    "\n",
    "            if teacher_forcing and tgt_indices is not None:\n",
    "                idx_t = tgt_indices[:, t]\n",
    "            else:\n",
    "                probs = F.softmax(scores, dim=-1)\n",
    "                idx_t = probs.argmax(dim=-1)\n",
    "                new_visit = F.one_hot(idx_t, num_classes=S).bool()\n",
    "                current_mask = current_mask | new_visit\n",
    "\n",
    "            next_emb = torch.gather(memory, 1, idx_t.view(B,1,1).expand(-1,1,d)).squeeze(1).unsqueeze(1)\n",
    "            decoder_inputs = torch.cat([decoder_inputs, next_emb], dim=1)\n",
    "\n",
    "        return torch.stack(logits_steps, dim=1)\n",
    "\n",
    "\n",
    "#  MODELO PRINCIPAL\n",
    "class EncoderPointerModel(nn.Module):\n",
    "    def __init__(self, input_dim=2, d_model=128, enc_layers=3, dec_layers=2, nhead=8, max_seq_len=128):\n",
    "        super().__init__()\n",
    "        # CORRECCI√ìN: Encoder ya no recibe max_seq_len\n",
    "        self.encoder = Encoder(\n",
    "            input_dim=input_dim,\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_layers=enc_layers\n",
    "        )\n",
    "        self.decoder = PointerDecoder(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_layers=dec_layers,\n",
    "            max_seq_len=max_seq_len\n",
    "        )\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, tgt_indices=None, mask_padding=None,\n",
    "                mask_visited=None, teacher_forcing=True,\n",
    "                return_probabilities=False):\n",
    "\n",
    "        memory = self.encoder(x, src_key_padding_mask=mask_padding)\n",
    "\n",
    "        logits = self.decoder(\n",
    "            memory,\n",
    "            tgt_indices=tgt_indices,\n",
    "            mask_visited=mask_visited,\n",
    "            teacher_forcing=teacher_forcing\n",
    "        )\n",
    "\n",
    "        if return_probabilities:\n",
    "            return torch.softmax(logits, dim=-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653e886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 3. UTILIDADES DE EVALUACI√ìN\n",
    "# ==========================================\n",
    "def calculate_gap(model, loader, device):\n",
    "    \"\"\"Calcula el Optimality GAP (%) usando Greedy Decoding en un batch.\"\"\"\n",
    "    model.eval()\n",
    "    try:\n",
    "        # Tomamos solo el primer batch para no demorar el entrenamiento\n",
    "        batch_x, batch_y = next(iter(loader))\n",
    "    except StopIteration:\n",
    "        return 0.0 # Loader vac√≠o\n",
    "\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "    batch_size, n_nodes, _ = batch_x.size()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Inferencia Greedy (Teacher Forcing = False)\n",
    "        # El modelo genera la secuencia de √≠ndices autom√°ticamente\n",
    "        logits = model(batch_x, teacher_forcing=False)\n",
    "        # logits: [Batch, N, N_nodes]\n",
    "\n",
    "        pred_indices = logits.argmax(dim=2) # [Batch, N]\n",
    "\n",
    "        # Stackear para formar tour\n",
    "        pred_tour = pred_indices\n",
    "\n",
    "    # --- C√°lculo de Distancias ---\n",
    "    def get_dist(pts, idx):\n",
    "        # pts: [B, N, 2], idx: [B, N]\n",
    "        gathered = torch.gather(pts, 1, idx.unsqueeze(-1).expand(-1, -1, 2))\n",
    "        next_pts = torch.roll(gathered, -1, dims=1)\n",
    "        return torch.norm(gathered - next_pts, dim=2).sum(dim=1)\n",
    "\n",
    "    cost_model = get_dist(batch_x, pred_tour)\n",
    "    cost_oracle = get_dist(batch_x, batch_y)\n",
    "\n",
    "    gap = ((cost_model - cost_oracle) / cost_oracle).mean().item() * 100\n",
    "    return gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34631666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ INICIANDO ENTRENAMIENTO SOTA (Multi-Archivo)\n",
      "\n",
      "============================================================\n",
      "üéì FASE ACTUAL: EASY | Epochs: 20\n",
      "============================================================\n",
      "‚ö†Ô∏è ALERTA: No encontr√© datos en d:\\VISUAL\\gith\\TransformerTSP\\data_repo\\EASY. Saltando fase.\n",
      "\n",
      "============================================================\n",
      "üéì FASE ACTUAL: MEDIUM | Epochs: 15\n",
      "============================================================\n",
      "üìÇ Archivos detectados: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     57\u001b[39m optimizer.zero_grad()\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Teacher Forcing: Pasamos la soluci√≥n completa (batch_y) como target\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# logits: [Batch, Seq, N_ciudades]\u001b[39;00m\n\u001b[32m     62\u001b[39m \n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Aplanar para Loss\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# logits.reshape(-1, logits.size(-1)) -> [Batch*Seq, N_ciudades]\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# batch_y.reshape(-1) -> [Batch*Seq]\u001b[39;00m\n\u001b[32m     66\u001b[39m loss = criterion(logits.reshape(-\u001b[32m1\u001b[39m, logits.size(-\u001b[32m1\u001b[39m)), batch_y.reshape(-\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mEncoderPointerModel.forward\u001b[39m\u001b[34m(self, x, tgt_indices, mask_padding, mask_visited, teacher_forcing, return_probabilities)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, tgt_indices=\u001b[38;5;28;01mNone\u001b[39;00m, mask_padding=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    107\u001b[39m             mask_visited=\u001b[38;5;28;01mNone\u001b[39;00m, teacher_forcing=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    108\u001b[39m             return_probabilities=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    110\u001b[39m     memory = \u001b[38;5;28mself\u001b[39m.encoder(x, src_key_padding_mask=mask_padding)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask_visited\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_visited\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mteacher_forcing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mteacher_forcing\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_probabilities:\n\u001b[32m    120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m torch.softmax(logits, dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mPointerDecoder.forward\u001b[39m\u001b[34m(self, memory, tgt_indices, mask_visited, teacher_forcing)\u001b[39m\n\u001b[32m     60\u001b[39m dec_out = \u001b[38;5;28mself\u001b[39m.decoder(dec_in, memory, memory_key_padding_mask=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     62\u001b[39m q_t = dec_out[:, -\u001b[32m1\u001b[39m, :]\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m q = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquery_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_t\u001b[49m\u001b[43m)\u001b[49m.unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m     65\u001b[39m scores = torch.matmul(q, memory.transpose(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m)) / math.sqrt(d)\n\u001b[32m     66\u001b[39m scores = scores.squeeze(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 4. BUCLE DE ENTRENAMIENTO (LAZY LOADING)\n",
    "# ==========================================\n",
    "\n",
    "# Instanciar Modelo con la nueva clase\n",
    "model = EncoderPointerModel(input_dim=2, d_model=128, nhead=8, enc_layers=3, dec_layers=2, max_seq_len=150).to(DEVICE) # Ajusta max_seq_len seg√∫n tus datos m√°s grandes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\nüöÄ INICIANDO ENTRENAMIENTO SOTA (Multi-Archivo)\")\n",
    "\n",
    "for stage in CURRICULUM:\n",
    "    phase = stage['phase']\n",
    "    folder_path = PATHS[phase]\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üéì FASE ACTUAL: {phase} | Epochs: {stage['epochs']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Buscar archivos .npz y .tpz\n",
    "    all_files = glob.glob(os.path.join(folder_path, \"*.npz\")) + \\\n",
    "                glob.glob(os.path.join(folder_path, \"*.tpz\"))\n",
    "\n",
    "    if not all_files:\n",
    "        print(f\"‚ö†Ô∏è ALERTA: No encontr√© datos en {folder_path}. Saltando fase.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"üìÇ Archivos detectados: {len(all_files)}\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=stage['lr'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "    for epoch in range(stage['epochs']):\n",
    "        model.train()\n",
    "        epoch_loss_accum = 0\n",
    "        total_batches = 0\n",
    "        current_gap = 0\n",
    "\n",
    "        # --- BUCLE SOBRE ARCHIVOS (Lazy Loading) ---\n",
    "        for file_idx, file_path in enumerate(all_files):\n",
    "            try:\n",
    "                # 1. Cargar Archivo a RAM\n",
    "                data = np.load(file_path)\n",
    "                points = torch.FloatTensor(data['points'])\n",
    "                solutions = torch.LongTensor(data['solutions'])\n",
    "\n",
    "                # Normalizaci√≥n defensiva\n",
    "                if points.max() > 1.0: points /= points.max()\n",
    "\n",
    "                dataset = TensorDataset(points, solutions)\n",
    "                loader = DataLoader(dataset, batch_size=stage['bs'], shuffle=True)\n",
    "\n",
    "                # 2. Entrenar sobre este archivo\n",
    "                pbar = tqdm(loader, desc=f\"Ep {epoch+1} | {os.path.basename(file_path)}\", leave=False)\n",
    "\n",
    "                for batch_x, batch_y in pbar:\n",
    "                    batch_x, batch_y = batch_x.to(DEVICE), batch_y.to(DEVICE)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Teacher Forcing: Pasamos la soluci√≥n completa (batch_y) como target\n",
    "                    logits = model(batch_x, tgt_indices=batch_y, teacher_forcing=True)\n",
    "                    # logits: [Batch, Seq, N_ciudades]\n",
    "\n",
    "                    # Aplanar para Loss\n",
    "                    # logits.reshape(-1, logits.size(-1)) -> [Batch*Seq, N_ciudades]\n",
    "                    # batch_y.reshape(-1) -> [Batch*Seq]\n",
    "                    loss = criterion(logits.reshape(-1, logits.size(-1)), batch_y.reshape(-1))\n",
    "\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss_accum += loss.item()\n",
    "                    pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "                total_batches += len(loader)\n",
    "\n",
    "                # Calcular GAP solo en el √∫ltimo archivo de la √©poca para ahorrar tiempo\n",
    "                if file_idx == len(all_files) - 1:\n",
    "                    current_gap = calculate_gap(model, loader, DEVICE)\n",
    "\n",
    "                # 3. LIMPIEZA DE MEMORIA\n",
    "                del data, points, solutions, dataset, loader\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error leyendo archivo {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # --- REPORTE DE √âPOCA ---\n",
    "        avg_loss = epoch_loss_accum / total_batches if total_batches > 0 else 0\n",
    "        print(f\"    üìâ Epoca {epoch+1} Terminada | Loss: {avg_loss:.4f} | üìä GAP: {current_gap:.2f}%\")\n",
    "\n",
    "        # Scheduler Step\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "        # Guardar Checkpoint\n",
    "        save_file = os.path.join(folder_path, f\"checkpoint_{phase}_best.pth\")\n",
    "        torch.save(model.state_dict(), save_file)\n",
    "\n",
    "print(\"\\nüèÜ ENTRENAMIENTO COMPLETADO EXITOSAMENTE.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
