{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e36a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 0. IMPORTS\n",
    "# ==========================================\n",
    "\n",
    "#probando si esto se commitea Segunda prueba desde otro pc\n",
    "#Nota de intiti: si van a trabajar desde un entorno local (Visual), \n",
    "# aseg√∫rense de tener instaladas las librer√≠as necesarias.\n",
    "#tutorial: ctrl + √± para abrir el terminal y luego pegar los siguientes comandos:\n",
    "#comando para instalar torch: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -> En caso que quieran usar GPU.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from ortools.constraint_solver import pywrapcp, routing_enums_pb2\n",
    "import concurrent.futures # LIBRER√çA MAGICA PARA PARALELISMO\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import requests \n",
    "import gc # Garbage Collector para gesti√≥n de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e8365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è GPU NO DETECTADA: Entrenando en CPU (ser√° lento).\n",
      "\n",
      "‚öôÔ∏è Sincronizando con GitHub (felipe-astudillo-s/TransformerTSP)...\n",
      "üîç Consultando API para: Data/Easy...\n",
      "‚úÖ Fase Data/Easy: 20 archivos listos en c:\\Users\\intix\\OneDrive\\Documentos\\DeltaDefiitive\\TransformerTSP\\data_repo\\EASY\n",
      "üîç Consultando API para: Data/Medium...\n",
      "‚úÖ Fase Data/Medium: 20 archivos listos en c:\\Users\\intix\\OneDrive\\Documentos\\DeltaDefiitive\\TransformerTSP\\data_repo\\MEDIUM\n",
      "üîç Consultando API para: Data/Hard...\n",
      "‚úÖ Fase Data/Hard: 10 archivos listos en c:\\Users\\intix\\OneDrive\\Documentos\\DeltaDefiitive\\TransformerTSP\\data_repo\\HARD\n",
      "\n",
      "üìÇ Rutas configuradas correctamente.\n",
      "üöÄ Listo para ejecutar el Bloque de Entrenamiento.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURACI√ìN, GPU Y DESCARGA DE DATOS\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# --- A. CONFIGURACI√ìN DEL HARDWARE (DEVICE) ---\n",
    "# Esto es vital para que el Bloque de entrenamiento sepa qu√© usar\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(f\"‚úÖ GPU DETECTADA: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   (Memoria disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB)\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"‚ö†Ô∏è GPU NO DETECTADA: Entrenando en CPU (ser√° lento).\")\n",
    "\n",
    "# --- B. CONFIGURACI√ìN DEL REPOSITORIO ---\n",
    "REPO_USER = \"felipe-astudillo-s\"\n",
    "REPO_NAME = \"TransformerTSP\"\n",
    "BRANCH = \"main\" # ‚ö†Ô∏è IMPORTANTE: Si tus datos no est√°n en 'main', cambia esto por el nombre de tu rama o commit.\n",
    "\n",
    "REPO_FOLDERS = {\n",
    "    \"EASY\":   \"Data/Easy\",\n",
    "    \"MEDIUM\": \"Data/Medium\",\n",
    "    \"HARD\":   \"Data/Hard\"\n",
    "}\n",
    "\n",
    "BASE_LOCAL_DIR = os.path.join(os.getcwd(), \"data_repo\")\n",
    "\n",
    "def download_folder_from_github(user, repo, repo_folder_path, local_output_dir, branch=\"main\"):\n",
    "    \"\"\"Descarga todos los .npz de una carpeta de GitHub usando la API.\"\"\"\n",
    "    api_url = f\"https://api.github.com/repos/{user}/{repo}/contents/{repo_folder_path}?ref={branch}\"\n",
    "    \n",
    "    print(f\"üîç Consultando API para: {repo_folder_path}...\")\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 404:\n",
    "            print(f\"‚ùå Error 404: No existe la carpeta '{repo_folder_path}' en la rama '{branch}'.\")\n",
    "            return local_output_dir\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Error API ({response.status_code}): {response.text}\")\n",
    "            return local_output_dir\n",
    "\n",
    "        files_list = response.json()\n",
    "        \n",
    "        if not os.path.exists(local_output_dir):\n",
    "            os.makedirs(local_output_dir)\n",
    "\n",
    "        if isinstance(files_list, dict) and 'message' in files_list:\n",
    "            print(\"‚ùå Error: La ruta parece no ser una carpeta v√°lida.\")\n",
    "            return local_output_dir\n",
    "\n",
    "        count = 0\n",
    "        for item in files_list:\n",
    "            if item['type'] == 'file' and item['name'].endswith('.npz'):\n",
    "                local_path = os.path.join(local_output_dir, item['name'])\n",
    "                if not os.path.exists(local_path):\n",
    "                    try:\n",
    "                        r = requests.get(item['download_url'])\n",
    "                        with open(local_path, 'wb') as f:\n",
    "                            f.write(r.content)\n",
    "                        count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"  ‚ùå Fall√≥ {item['name']}: {e}\")\n",
    "                else:\n",
    "                    count += 1 # Ya exist√≠a\n",
    "        \n",
    "        print(f\"‚úÖ Fase {repo_folder_path}: {count} archivos listos en {local_output_dir}\")\n",
    "        return local_output_dir\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error de conexi√≥n: {e}\")\n",
    "        return local_output_dir\n",
    "\n",
    "# --- C. EJECUCI√ìN DE DESCARGA ---\n",
    "PATHS = {}\n",
    "print(f\"\\n‚öôÔ∏è Sincronizando con GitHub ({REPO_USER}/{REPO_NAME})...\")\n",
    "\n",
    "for phase_name, repo_path in REPO_FOLDERS.items():\n",
    "    local_target = os.path.join(BASE_LOCAL_DIR, phase_name)\n",
    "    final_path = download_folder_from_github(REPO_USER, REPO_NAME, repo_path, local_target, BRANCH)\n",
    "    PATHS[phase_name] = final_path\n",
    "\n",
    "# --- D. CURRICULUM ---\n",
    "CURRICULUM = [\n",
    "    {\"phase\": \"EASY\",   \"epochs\": 20, \"lr\": 1e-3, \"bs\": 128},\n",
    "    {\"phase\": \"MEDIUM\", \"epochs\": 15, \"lr\": 1e-4, \"bs\": 64},\n",
    "    {\"phase\": \"HARD\",   \"epochs\": 30, \"lr\": 1e-4, \"bs\": 32}\n",
    "]\n",
    "\n",
    "print(f\"\\nüìÇ Rutas configuradas correctamente.\")\n",
    "print(f\"üöÄ Listo para ejecutar el Bloque de Entrenamiento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b3c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f875db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. Modelo\n",
    "# ==========================================\n",
    "\n",
    "class EncoderPointerModel(nn.Module):\n",
    "    def __init__(self, input_dim=2, d_model=64, nhead=8, enc_layers=3, dec_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. EMBEDDING & ENCODER (El \"Mapa\")\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=512, dropout=dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=enc_layers)\n",
    "        \n",
    "        # 2. DECODER (El \"Navegante\")\n",
    "        # Usamos standard TransformerDecoder. Nota: El decoder necesita una memoria (encoder output)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=512, dropout=dropout, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=dec_layers)\n",
    "        \n",
    "        # 3. COMPONENTES DE \"POINTING\"\n",
    "        self.start_token = nn.Parameter(torch.randn(1, 1, d_model)) # Token de inicio\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Proyecci√≥n para la Query\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, tgt_indices=None, teacher_forcing=True):\n",
    "        \"\"\"\n",
    "        x: [Batch, N, 2] (Coordenadas)\n",
    "        tgt_indices: [Batch, N] (Indices de la ruta real, para entrenamiento)\n",
    "        \"\"\"\n",
    "        Batch, N, _ = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        # --- A. ENCODER ---\n",
    "        # 1. Convertir coordenadas a vectores\n",
    "        h = self.embedding(x)  # [B, N, d_model]\n",
    "        # 2. Procesar contexto global\n",
    "        memory = self.encoder(h) # [B, N, d_model]\n",
    "\n",
    "        # --- B. DECODER LOOP ---\n",
    "        # Preparamos el bucle\n",
    "        decoder_input = self.start_token.expand(Batch, -1, -1) # [B, 1, d_model]\n",
    "        \n",
    "        # M√°scaras\n",
    "        visited_mask = torch.zeros(Batch, N, dtype=torch.bool, device=device)\n",
    "        logits_list = []\n",
    "        \n",
    "        # Si teacher_forcing=True, iteramos N veces (largo del tour). Si no, tambi√©n.\n",
    "        steps = N \n",
    "        \n",
    "        for t in range(steps):\n",
    "            # 1. Pasamos por el Transformer Decoder Est√°ndar\n",
    "            # dec_out: [B, 1, d_model] (El \"pensamiento\" actual del decoder)\n",
    "            dec_out = self.decoder(tgt=decoder_input, memory=memory)\n",
    "            \n",
    "            # 2. MECANISMO DE POINTER (Atenci√≥n)\n",
    "            # Calculamos qu√© tanto se parece el pensamiento actual (Query) a cada ciudad en memoria (Key)\n",
    "            query = self.W_q(dec_out) # [B, 1, d_model]\n",
    "            \n",
    "            # Score = Query ‚Ä¢ Memory_Transpuesta\n",
    "            # [B, 1, d] x [B, d, N] -> [B, 1, N]\n",
    "            scores = torch.matmul(query, memory.transpose(1, 2)) / math.sqrt(self.d_model)\n",
    "            scores = scores.squeeze(1) # [B, N]\n",
    "\n",
    "            # 3. ENMASCARAR VISITADOS (Para no repetir ciudades)\n",
    "            if not teacher_forcing:\n",
    "                scores = scores.masked_fill(visited_mask, float('-inf'))\n",
    "\n",
    "            logits_list.append(scores)\n",
    "\n",
    "            # 4. PREPARAR ENTRADA PARA EL SIGUIENTE PASO\n",
    "            if teacher_forcing and tgt_indices is not None:\n",
    "                # Entrenamiento: Usamos la ciudad real que debi√≥ visitar\n",
    "                next_idx = tgt_indices[:, t]\n",
    "            else:\n",
    "                # Inferencia: Usamos la ciudad que el modelo acaba de elegir (Greedy)\n",
    "                probs = F.softmax(scores, dim=-1)\n",
    "                next_idx = probs.argmax(dim=-1)\n",
    "                \n",
    "                # Actualizar m√°scara de visitados\n",
    "                visited_mask.scatter_(1, next_idx.unsqueeze(1), True)\n",
    "\n",
    "            # Buscamos el embedding de la ciudad elegida en la memoria\n",
    "            # [B, 1, d_model]\n",
    "            next_input = torch.gather(memory, 1, next_idx.view(Batch, 1, 1).expand(-1, -1, self.d_model))\n",
    "            \n",
    "            # Actualizamos la entrada del decoder para la siguiente vuelta\n",
    "            decoder_input = next_input\n",
    "\n",
    "        # Retornamos todos los pasos apilados: [B, N, N]\n",
    "        return torch.stack(logits_list, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "653e886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 3. UTILIDADES DE EVALUACI√ìN\n",
    "# ==========================================\n",
    "def calculate_gap(model, loader, device):\n",
    "    \"\"\"Calcula el Optimality GAP (%) usando Greedy Decoding en un batch.\"\"\"\n",
    "    model.eval()\n",
    "    try:\n",
    "        # Tomamos solo el primer batch para no demorar el entrenamiento\n",
    "        batch_x, batch_y = next(iter(loader))\n",
    "    except StopIteration:\n",
    "        return 0.0 # Loader vac√≠o\n",
    "\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "    batch_size, n_nodes, _ = batch_x.size()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Inferencia Greedy (Teacher Forcing = False)\n",
    "        # El modelo genera la secuencia de √≠ndices autom√°ticamente\n",
    "        logits = model(batch_x, teacher_forcing=False)\n",
    "        # logits: [Batch, N, N_nodes]\n",
    "\n",
    "        pred_indices = logits.argmax(dim=2) # [Batch, N]\n",
    "\n",
    "        # Stackear para formar tour\n",
    "        pred_tour = pred_indices\n",
    "\n",
    "    # --- C√°lculo de Distancias ---\n",
    "    def get_dist(pts, idx):\n",
    "        # pts: [B, N, 2], idx: [B, N]\n",
    "        gathered = torch.gather(pts, 1, idx.unsqueeze(-1).expand(-1, -1, 2))\n",
    "        next_pts = torch.roll(gathered, -1, dims=1)\n",
    "        return torch.norm(gathered - next_pts, dim=2).sum(dim=1)\n",
    "\n",
    "    cost_model = get_dist(batch_x, pred_tour)\n",
    "    cost_oracle = get_dist(batch_x, batch_y)\n",
    "\n",
    "    gap = ((cost_model - cost_oracle) / cost_oracle).mean().item() * 100\n",
    "    return gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4048fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ INICIANDO ENTRENAMIENTO (Simplified Pointer Network)\n",
      "\n",
      "============================================================\n",
      "üéì FASE ACTUAL: EASY | Epochs: 20\n",
      "============================================================\n",
      "üìÇ Archivos detectados: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     67\u001b[39m optimizer.zero_grad()\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# A. Forward Pass (Entrenamiento con Teacher Forcing impl√≠cito al pasar tgt_indices)\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# batch_x: [Batch, N, 2]\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# batch_y: [Batch, N] (Indices de la ruta √≥ptima)\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# logits: [Batch, N, N] (Probabilidades para cada paso)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# B. Calcular Loss\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Aplanamos:\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# logits -> [Batch * N, N] (Predicciones para cada paso de cada tour)\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# batch_y -> [Batch * N] (Target real para cada paso)\u001b[39;00m\n\u001b[32m     79\u001b[39m loss = criterion(logits.reshape(-\u001b[32m1\u001b[39m, logits.size(-\u001b[32m1\u001b[39m)), batch_y.reshape(-\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mSimplifiedPointerNetwork.forward\u001b[39m\u001b[34m(self, x, tgt_indices, teacher_forcing)\u001b[39m\n\u001b[32m     48\u001b[39m steps = N \n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# 1. Pasamos por el Transformer Decoder Est√°ndar\u001b[39;00m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# dec_out: [B, 1, d_model] (El \"pensamiento\" actual del decoder)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     dec_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# 2. MECANISMO DE POINTER (Atenci√≥n)\u001b[39;00m\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Calculamos qu√© tanto se parece el pensamiento actual (Query) a cada ciudad en memoria (Key)\u001b[39;00m\n\u001b[32m     57\u001b[39m     query = \u001b[38;5;28mself\u001b[39m.W_q(dec_out) \u001b[38;5;66;03m# [B, 1, d_model]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:628\u001b[39m, in \u001b[36mTransformerDecoder.forward\u001b[39m\u001b[34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m    625\u001b[39m tgt_is_causal = _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    640\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.norm(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:1131\u001b[39m, in \u001b[36mTransformerDecoderLayer.forward\u001b[39m\u001b[34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m   1122\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m   1123\u001b[39m         x + \u001b[38;5;28mself\u001b[39m._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[32m   1124\u001b[39m     )\n\u001b[32m   1125\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(\n\u001b[32m   1126\u001b[39m         x\n\u001b[32m   1127\u001b[39m         + \u001b[38;5;28mself\u001b[39m._mha_block(\n\u001b[32m   1128\u001b[39m             x, memory, memory_mask, memory_key_padding_mask, memory_is_causal\n\u001b[32m   1129\u001b[39m         )\n\u001b[32m   1130\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm3(x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:1176\u001b[39m, in \u001b[36mTransformerDecoderLayer._ff_block\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1176\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.linear2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout3(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\dropout.py:73\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:1418\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. BUCLE DE ENTRENAMIENTO (LAZY LOADING) - SIMPLIFICADO\n",
    "# ==========================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Instanciar Modelo Simplificado\n",
    "# Ajusta input_dim=2 (x,y), d_model=128, etc.\n",
    "model = SimplifiedPointerNetwork(input_dim=2, d_model=128, nhead=8, enc_layers=3, dec_layers=2).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\nüöÄ INICIANDO ENTRENAMIENTO (Simplified Pointer Network)\")\n",
    "\n",
    "for stage in CURRICULUM:\n",
    "    phase = stage['phase']\n",
    "    folder_path = PATHS[phase]\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üéì FASE ACTUAL: {phase} | Epochs: {stage['epochs']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Buscar archivos .npz\n",
    "    all_files = glob.glob(os.path.join(folder_path, \"*.npz\"))\n",
    "\n",
    "    if not all_files:\n",
    "        print(f\"‚ö†Ô∏è ALERTA: No encontr√© datos en {folder_path}. Saltando fase.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"üìÇ Archivos detectados: {len(all_files)}\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=stage['lr'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "    for epoch in range(stage['epochs']):\n",
    "        model.train()\n",
    "        epoch_loss_accum = 0\n",
    "        total_batches = 0\n",
    "        current_gap = 0\n",
    "\n",
    "        # --- BUCLE SOBRE ARCHIVOS (Lazy Loading) ---\n",
    "        for file_idx, file_path in enumerate(all_files):\n",
    "            try:\n",
    "                # 1. Cargar Archivo a RAM\n",
    "                data = np.load(file_path)\n",
    "                points = torch.FloatTensor(data['points'])\n",
    "                solutions = torch.LongTensor(data['solutions'])\n",
    "\n",
    "                # Normalizaci√≥n defensiva (0-1)\n",
    "                if points.max() > 1.0: points /= points.max()\n",
    "\n",
    "                dataset = TensorDataset(points, solutions)\n",
    "                loader = DataLoader(dataset, batch_size=stage['bs'], shuffle=True)\n",
    "\n",
    "                # 2. Entrenar sobre este archivo\n",
    "                pbar = tqdm(loader, desc=f\"Ep {epoch+1} | {os.path.basename(file_path)}\", leave=False)\n",
    "\n",
    "                for batch_x, batch_y in pbar:\n",
    "                    batch_x, batch_y = batch_x.to(DEVICE), batch_y.to(DEVICE)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # A. Forward Pass (Entrenamiento con Teacher Forcing impl√≠cito al pasar tgt_indices)\n",
    "                    # batch_x: [Batch, N, 2]\n",
    "                    # batch_y: [Batch, N] (Indices de la ruta √≥ptima)\n",
    "                    # logits: [Batch, N, N] (Probabilidades para cada paso)\n",
    "                    logits = model(batch_x, tgt_indices=batch_y, teacher_forcing=True)\n",
    "\n",
    "                    # B. Calcular Loss\n",
    "                    # Aplanamos:\n",
    "                    # logits -> [Batch * N, N] (Predicciones para cada paso de cada tour)\n",
    "                    # batch_y -> [Batch * N] (Target real para cada paso)\n",
    "                    loss = criterion(logits.reshape(-1, logits.size(-1)), batch_y.reshape(-1))\n",
    "\n",
    "                    # C. Backward Pass\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Evita explosi√≥n de gradientes\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss_accum += loss.item()\n",
    "                    pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "                total_batches += len(loader)\n",
    "\n",
    "                # Calcular GAP solo en el √∫ltimo archivo de la √©poca para ahorrar tiempo\n",
    "                # Nota: Aseg√∫rate de que calculate_gap est√© definida y use teacher_forcing=False\n",
    "                if file_idx == len(all_files) - 1:\n",
    "                     current_gap = calculate_gap(model, loader, DEVICE)\n",
    "\n",
    "                # 3. LIMPIEZA DE MEMORIA\n",
    "                del data, points, solutions, dataset, loader\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error leyendo archivo {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # --- REPORTE DE √âPOCA ---\n",
    "        avg_loss = epoch_loss_accum / total_batches if total_batches > 0 else 0\n",
    "        print(f\"    üìâ Epoca {epoch+1} Terminada | Loss: {avg_loss:.4f} | üìä GAP: {current_gap:.2f}%\")\n",
    "\n",
    "        # Scheduler Step\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "        # Guardar Checkpoint\n",
    "        save_file = os.path.join(folder_path, f\"checkpoint_{phase}_best.pth\")\n",
    "        torch.save(model.state_dict(), save_file)\n",
    "\n",
    "print(\"\\nüèÜ ENTRENAMIENTO COMPLETADO EXITOSAMENTE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e60dd6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä VALIDANDO FASE: EASY (MODO COMPLETO)\n",
      "============================================================\n",
      "‚ö†Ô∏è Salto Fase: No existe checkpoint en data_repo/EASY/checkpoint_EASY_best.pth\n",
      "\n",
      "============================================================\n",
      "üìä VALIDANDO FASE: MEDIUM (MODO COMPLETO)\n",
      "============================================================\n",
      "‚ö†Ô∏è Salto Fase: No existe checkpoint en data_repo/MEDIUM/checkpoint_MEDIUM_best.pth\n",
      "\n",
      "============================================================\n",
      "üìä VALIDANDO FASE: HARD (MODO COMPLETO)\n",
      "============================================================\n",
      "‚ö†Ô∏è Salto Fase: No existe checkpoint en data_repo/HARD/checkpoint_HARD_best.pth\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. VALIDACI√ìN FINAL COMPLETA (MULTI-PART)\n",
    "# ==========================================\n",
    "\n",
    "# --- CONFIGURACI√ìN DE RUTAS ---\n",
    "PATHS_CONFIG = {\n",
    "    \"EASY\": {\n",
    "        \"ckpt\": \"data_repo/EASY/checkpoint_EASY_best.pth\",\n",
    "        \"val_folder\": \"Data/Validation/Easy\",\n",
    "        \"val_prefix\": \"tsp_easy\"\n",
    "    },\n",
    "    \"MEDIUM\": {\n",
    "        \"ckpt\": \"data_repo/MEDIUM/checkpoint_MEDIUM_best.pth\",\n",
    "        \"val_folder\": \"Data/Validation/Medium\",\n",
    "        \"val_prefix\": \"tsp_medium\"\n",
    "    },\n",
    "    \"HARD\": {\n",
    "        \"ckpt\": \"data_repo/HARD/checkpoint_HARD_best.pth\",\n",
    "        \"val_folder\": \"Data/Validation/Hard\",\n",
    "        \"val_prefix\": \"tsp_hard\"\n",
    "    }\n",
    "}\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_tour_distance(points, tour_indices):\n",
    "    \"\"\"Calcula distancia total de la ruta.\"\"\"\n",
    "    gathered = torch.gather(points, 1, tour_indices.unsqueeze(-1).expand(-1, -1, 2))\n",
    "    next_pts = torch.roll(gathered, -1, dims=1)\n",
    "    dist = torch.norm(gathered - next_pts, dim=2).sum(dim=1)\n",
    "    return dist\n",
    "\n",
    "def load_all_validation_parts(folder, prefix):\n",
    "    \"\"\"\n",
    "    Busca TODAS las partes (part_0, part_1...) y las une en un solo dataset gigante.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"‚ùå Carpeta no existe: {folder}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Buscar todos los archivos que coincidan\n",
    "    search_pattern = os.path.join(folder, f\"{prefix}*.npz\")\n",
    "    all_files = sorted(glob.glob(search_pattern))\n",
    "    \n",
    "    if not all_files:\n",
    "        print(f\"‚ùå No encontr√© archivos {prefix}*.npz en {folder}\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"üìö Uniendo {len(all_files)} archivos de validaci√≥n encontrados...\")\n",
    "    \n",
    "    all_points = []\n",
    "    all_solutions = []\n",
    "    \n",
    "    for f_path in all_files:\n",
    "        try:\n",
    "            data = np.load(f_path, allow_pickle=True)\n",
    "            all_points.append(data['points'])\n",
    "            \n",
    "            # Conversi√≥n m√°gica de lista de objetos a matriz int64\n",
    "            raw_sols = data['solutions']\n",
    "            # Verificamos si ya es matriz o lista de listas\n",
    "            if raw_sols.dtype == np.object_:\n",
    "                sols_mat = np.vstack(raw_sols).astype(np.int64)\n",
    "            else:\n",
    "                sols_mat = raw_sols.astype(np.int64)\n",
    "                \n",
    "            all_solutions.append(sols_mat)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error leyendo {os.path.basename(f_path)}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_points:\n",
    "        return None, None\n",
    "\n",
    "    # Pegamos todo en arrays gigantes\n",
    "    # np.concatenate une los arrays uno detr√°s de otro\n",
    "    final_points = np.concatenate(all_points) \n",
    "    final_solutions = np.concatenate(all_solutions)\n",
    "    \n",
    "    return torch.FloatTensor(final_points), torch.from_numpy(final_solutions)\n",
    "\n",
    "def validate_phase(phase_name, config):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìä VALIDANDO FASE: {phase_name} (MODO COMPLETO)\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # 1. Cargar Checkpoint\n",
    "    if not os.path.exists(config[\"ckpt\"]):\n",
    "        print(f\"‚ö†Ô∏è Salto Fase: No existe checkpoint en {config['ckpt']}\")\n",
    "        return\n",
    "\n",
    "    model = EncoderPointerModel(input_dim=2, d_model=128, nhead=8, enc_layers=3, dec_layers=2, max_seq_len=150).to(DEVICE)\n",
    "    \n",
    "    try:\n",
    "        model.load_state_dict(torch.load(config[\"ckpt\"], map_location=DEVICE, weights_only=False))\n",
    "        model.eval()\n",
    "        print(f\"üß† Modelo cargado: {os.path.basename(config['ckpt'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error cargando modelo: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Cargar TODA la data\n",
    "    points, solutions = load_all_validation_parts(config[\"val_folder\"], config[\"val_prefix\"])\n",
    "    \n",
    "    if points is None:\n",
    "        return\n",
    "    \n",
    "    print(f\"üìÇ Total muestras cargadas: {len(points)}\")\n",
    "    \n",
    "    # Normalizaci√≥n\n",
    "    if points.max() > 1.0: points /= points.max()\n",
    "\n",
    "    # Dataset completo\n",
    "    dataset = TensorDataset(points, solutions)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False) # Batch grande para ir r√°pido\n",
    "\n",
    "    # 3. Inferencia\n",
    "    gap_accum = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Benchmarking\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for bx, by in pbar:\n",
    "            bx, by = bx.to(DEVICE), by.to(DEVICE)\n",
    "            \n",
    "            logits = model(bx, teacher_forcing=False)\n",
    "            pred_tour = logits.argmax(dim=2) \n",
    "\n",
    "            cost_model = get_tour_distance(bx, pred_tour)\n",
    "            cost_ortools = get_tour_distance(bx, by)\n",
    "\n",
    "            gap = ((cost_model - cost_ortools) / cost_ortools)\n",
    "            gap_accum += gap.sum().item()\n",
    "            total_samples += bx.size(0)\n",
    "            \n",
    "            pbar.set_postfix({'GAP Acum': f\"{(gap_accum/total_samples)*100:.2f}%\"})\n",
    "\n",
    "    final_gap = (gap_accum / total_samples) * 100\n",
    "    print(f\"\\nüèÜ RESULTADO FINAL {phase_name}: GAP GLOBAL {final_gap:.2f}%\")\n",
    "\n",
    "# --- EJECUTAR ---\n",
    "# Nota: Como detuviste el entrenamiento en MEDIUM, probablemente solo EASY funcione bien.\n",
    "for phase in [\"EASY\", \"MEDIUM\", \"HARD\"]:\n",
    "    validate_phase(phase, PATHS_CONFIG[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd4b9b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "üß™ EXPERIMENTO: ¬øPuede un modelo de 20 ciudades resolver uno de 50?\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "üìä VALIDANDO FASE: GENERALIZATION_TEST (MODO COMPLETO)\n",
      "============================================================\n",
      "‚ö†Ô∏è Salto Fase: No existe checkpoint en data_repo/EASY/checkpoint_EASY_best.pth\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üß™ PRUEBA DE GENERALIZACI√ìN (EASY -> MEDIUM)\n",
    "# ==========================================\n",
    "\n",
    "# Definimos una configuraci√≥n h√≠brida:\n",
    "# üß† CEREBRO: Checkpoint de EASY (Entrenado con 20 nodos)\n",
    "# üìù EXAMEN: Datos de MEDIUM (Problemas de 50 nodos)\n",
    "\n",
    "CROSS_TEST_CONFIG = {\n",
    "    \"ckpt\": \"data_repo/EASY/checkpoint_EASY_best.pth\",   # Usamos el modelo peque√±o\n",
    "    \"val_folder\": \"Data/Validation/Medium\",              # Usamos la data mediana\n",
    "    \"val_prefix\": \"tsp_medium\"\n",
    "}\n",
    "\n",
    "print(f\"\\n{'#'*60}\")\n",
    "print(\"üß™ EXPERIMENTO: ¬øPuede un modelo de 20 ciudades resolver uno de 50?\")\n",
    "print(f\"{'#'*60}\")\n",
    "\n",
    "# Llamamos a tu funci√≥n de validaci√≥n existente\n",
    "validate_phase(\"GENERALIZATION_TEST\", CROSS_TEST_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bc9e1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé® GENERANDO VISUALIZACIONES PARA: EASY\n",
      "‚ö†Ô∏è No hay modelo para EASY, saltando...\n",
      "\n",
      "üé® GENERANDO VISUALIZACIONES PARA: MEDIUM\n",
      "‚ö†Ô∏è No hay modelo para MEDIUM, saltando...\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. VISUALIZACI√ìN COMPARATIVA (VISUALIZER)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "# Usamos la misma configuraci√≥n de rutas que antes\n",
    "PATHS_CONFIG = {\n",
    "    \"EASY\":   {\"ckpt\": \"data_repo/EASY/checkpoint_EASY_best.pth\",   \"val_folder\": \"Data/Validation/Easy\",   \"val_prefix\": \"tsp_easy\"},\n",
    "    \"MEDIUM\": {\"ckpt\": \"data_repo/MEDIUM/checkpoint_MEDIUM_best.pth\", \"val_folder\": \"Data/Validation/Medium\", \"val_prefix\": \"tsp_medium\"},\n",
    "    \"HARD\":   {\"ckpt\": \"data_repo/HARD/checkpoint_HARD_best.pth\",   \"val_folder\": \"Data/Validation/Hard\",   \"val_prefix\": \"tsp_hard\"}\n",
    "}\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def plot_route(ax, points, tour, title, color):\n",
    "    \"\"\"Dibuja una ruta en el subplot dado.\"\"\"\n",
    "    # points: array numpy [N, 2]\n",
    "    # tour: array numpy [N] (indices)\n",
    "    \n",
    "    # Reordenamos los puntos seg√∫n el tour\n",
    "    route_points = points[tour]\n",
    "    # Cerramos el ciclo (a√±adimos el primer punto al final)\n",
    "    route_points = np.vstack([route_points, route_points[0]])\n",
    "    \n",
    "    # Dibujar l√≠neas\n",
    "    ax.plot(route_points[:, 0], route_points[:, 1], c=color, linewidth=1.5, linestyle='-')\n",
    "    # Dibujar nodos\n",
    "    ax.scatter(points[:, 0], points[:, 1], c='black', s=15, zorder=5)\n",
    "    # Marcar inicio (rojo)\n",
    "    ax.scatter(route_points[0, 0], route_points[0, 1], c='red', s=40, zorder=6, label='Inicio')\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "def visualize_comparison(phase_name, config):\n",
    "    print(f\"\\nüé® GENERANDO VISUALIZACIONES PARA: {phase_name}\")\n",
    "    \n",
    "    if not os.path.exists(config[\"ckpt\"]):\n",
    "        print(f\"‚ö†Ô∏è No hay modelo para {phase_name}, saltando...\")\n",
    "        return\n",
    "\n",
    "    # 1. Cargar Modelo\n",
    "    model = EncoderPointerModel(input_dim=2, d_model=128, nhead=8, enc_layers=3, dec_layers=2, max_seq_len=150).to(DEVICE)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(config[\"ckpt\"], map_location=DEVICE, weights_only=False))\n",
    "        model.eval()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error cargando modelo: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Buscar archivos parciales\n",
    "    search_pattern = os.path.join(config[\"val_folder\"], f\"{config['val_prefix']}*.npz\")\n",
    "    files = sorted(glob.glob(search_pattern))\n",
    "    \n",
    "    if not files:\n",
    "        print(\"‚ùå No encontr√© archivos de validaci√≥n.\")\n",
    "        return\n",
    "\n",
    "    # 3. Iterar sobre cada archivo encontrado\n",
    "    print(f\"üì∏ Se encontraron {len(files)} archivos. Generando 1 ejemplo de cada uno...\")\n",
    "\n",
    "    for i, f_path in enumerate(files):\n",
    "        try:\n",
    "            # Cargar archivo\n",
    "            data = np.load(f_path, allow_pickle=True)\n",
    "            points_all = data['points']\n",
    "            sols_all = data['solutions']\n",
    "            \n",
    "            # --- SELECCIONAR UN EJEMPLO ALEATORIO O EL PRIMERO ---\n",
    "            idx = 0 # Tomamos el primero de cada archivo (puedes cambiar a np.random.randint)\n",
    "            \n",
    "            sample_points = points_all[idx] # [N, 2]\n",
    "            \n",
    "            # Fix conversi√≥n object -> int64 para la soluci√≥n real\n",
    "            raw_sol = sols_all[idx]\n",
    "            if isinstance(raw_sol, list) or raw_sol.dtype == np.object_:\n",
    "                 sample_sol_true = np.array(raw_sol).astype(np.int64)\n",
    "            else:\n",
    "                 sample_sol_true = raw_sol.astype(np.int64)\n",
    "\n",
    "            # Normalizar puntos para el modelo (0-1)\n",
    "            max_val = sample_points.max()\n",
    "            input_points = torch.tensor(sample_points / max_val, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "            # --- INFERENCIA DEL MODELO ---\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_points, teacher_forcing=False)\n",
    "                sample_sol_pred = logits.argmax(dim=2).squeeze(0).cpu().numpy()\n",
    "\n",
    "            # --- DIBUJAR ---\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            \n",
    "            # Gr√°fica Izquierda: Tu IA\n",
    "            plot_route(axs[0], sample_points, sample_sol_pred, f\"Tu Modelo (IA)\\nArchivo: {os.path.basename(f_path)}\", 'blue')\n",
    "            \n",
    "            # Gr√°fica Derecha: OR-Tools (El Maestro)\n",
    "            plot_route(axs[1], sample_points, sample_sol_true, \"OR-Tools (Ground Truth)\", 'green')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Limite de seguridad: Si hay 50 archivos, no queremos 50 popups.\n",
    "            # Comenta estas dos l√≠neas si quieres verlos TODOS.\n",
    "            if i >= 2: \n",
    "                print(\"üõë Deteniendo visualizaci√≥n para no saturar la pantalla (3 ejemplos mostrados).\")\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error visualizando {os.path.basename(f_path)}: {e}\")\n",
    "            continue\n",
    "\n",
    "# --- EJECUTAR ---\n",
    "visualize_comparison(\"EASY\", PATHS_CONFIG[\"EASY\"])\n",
    "visualize_comparison(\"MEDIUM\", PATHS_CONFIG[\"MEDIUM\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
